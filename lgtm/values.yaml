global:
  extraEnvFrom:
    - secretRef:
        name: lgtm-s3-creds
  extraEnv:
    - name: SSL_CERT_FILE
      value: /etc/ssl/certs/ca-certificates.crt
  extraVolumes:
    - name: ca-certificates
      configMap:
        name: trust-bundle
  extraVolumeMounts:
    - name: ca-certificates
      mountPath: /etc/ssl/certs
      readOnly: true

grafana:
  # https://github.com/grafana/helm-charts/blob/grafana-8.13.1/charts/grafana/values.yaml
  configMapAnnotations:
    argocd.argoproj.io/sync-options: Replace=true
  ingress:
    enabled: true
    ingressClassName: cilium
    annotations:
      cert-manager.io/cluster-issuer: real-cert
    hosts:
      - borgmon.local.symmatree.com
    tls:
      - secretName: grafana-tls
        hosts:
          - borgmon.local.symmatree.com
  persistence:
    enabled: true

  admin:
    existingSecret: "grafana-admin-user"
    userKey: username
    passwordKey: password

  plugins:
    - grafana-github-datasource
    - grafana-lokiexplore-app
    # - grafana-metricsdrilldown-app
    # - grafana-mqtt-datasource

  sidecar:
    dashboards:
      enabled: true
      searchNamespace: ALL
      # Let's see the default behavior first.
      # folderAnnotation: "grafana_dashboard_folder"
      provider:
        allowUiUpdates: true
    datasources:
      enabled: true
      searchNamespace: ALL
loki:
  loki:
    # Despite name this is actually multi-tenancy support.
    auth_enabled: false
    test:
      enabled: false
    # Cool but very chatty.
    lokiCanary:
      enabled: false
    commonConfig:
      replication_factor: 1
    schemaConfig:
      configs:
        - from: "2024-04-01"
          store: tsdb
          object_store: s3
          schema: v13
          index:
            prefix: loki_index_
            period: 24h
    extraMemberlistConfig:
      cluster_label: loki
    pattern_ingester:
      enabled: true
    limits_config:
      allow_structured_metadata: true
      volume_enabled: true
    ruler:
      enable_api: true

    storage:
      bucketNames:
        chunks: loki-chunks
        ruler: loki-ruler
        admin: loki-admin
      s3:
        # The output values if minio was enabled are found here:
        # https://github.com/grafana/loki/blob/main/production/helm/loki/templates/_helpers.tpl#L213C2-L218C17
        # We cannot directly use them but it is a good reference.
        endpoint: https://minio.tales-tenant.svc
        # For unclear reasons the Kubernetes dollar-paren syntax is not
        # expanded but this is Loki's native expansion syntax with config.expand-env=true
        secretAccessKey: "${SECRET_ACCESS_KEY}"
        accessKeyId: "${ACCESS_KEY_ID}"
        s3ForcePathStyle: true

  # We have minio at home.
  minio:
    enabled: false
  resultsCache:
    allocatedMemory: 128
  chunksCache:
    # in MB
    allocatedMemory: 512

  deploymentMode: SingleBinary
  singleBinary:
    replicas: 1
    persistence:
      enableStatefulSetAutoDeletePVC: true
      size: "10Gi"
    extraArgs:
      - -log-config-reverse-order
      - -config.expand-env=true
    extraEnv:
      - name: SSL_CERT_FILE
        value: /etc/ssl/certs/ca-certificates.crt
    extraEnvFrom:
      - secretRef:
          name: lgtm-s3-creds
    extraVolumes:
      - name: ca-certificates
        configMap:
          name: trust-bundle
    extraVolumeMounts:
      - name: ca-certificates
        mountPath: /etc/ssl/certs
        readOnly: true

  # Zero out replica counts of other deployment modes
  backend:
    replicas: 0
  read:
    replicas: 0
  write:
    replicas: 0

  ingester:
    replicas: 0
  querier:
    replicas: 0
  queryFrontend:
    replicas: 0
  queryScheduler:
    replicas: 0
  distributor:
    replicas: 0
  compactor:
    replicas: 0
  indexGateway:
    replicas: 0
  bloomCompactor:
    replicas: 0
  bloomGateway:
    replicas: 0

k8s-monitoring:
  cluster:
    name: tales
  destinations:
    - name: localMimir
      type: prometheus
      url: http://lgtm-mimir-nginx/api/prom/push
    - name: localLoki
      type: loki
      url: http://lgtm-loki-gateway/loki/api/v1/push

  # https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/charts/feature-cluster-metrics/values.yaml
  clusterMetrics:
    enabled: true
    controlPlane:
      enabled: true
    kubeProxy:
      # there isn't one, cilium replaces it.
      enabled: false
    windowsExporter:
      enabled: false
    kepler:
      enabled: false
    opencost:
      enabled: false
  clusterEvents:
    enabled: true
    # logfmt version does NO escaping:
    # https://github.com/grafana/alloy/blob/main/internal/component/loki/source/kubernetes_events/event_controller.go#L303
    # to
    # https://github.com/grafana/alloy/blob/main/internal/component/loki/source/kubernetes_events/event_controller.go#L324
    logFormat: json
  nodeLogs:
    # Talos doesn't surface these through the filesystem.
    enabled: false
  podLogs:
    enabled: true
  prometheusOperatorObjects:
    enabled: true
  alloy-metrics:
    enabled: true
  alloy-singleton:
    enabled: true
  alloy-logs:
    enabled: true
    alloy:
      mounts:
        # /var/log/pods and /var/log/containers exist. (Also audit.)
        varlog: true
        dockercontainers: false

  alloy-receiver:
    enabled: false
  integrations:
    alloy:
      instances:
        - name: alloy
          namespace: lgtm
          labelSelectors:
            app.kubernetes.io/name: [alloy-metrics, alloy-singleton, alloy-logs]
    cert-manager:
      instances:
        - name: cert-manager
          namespace: cert-manager
          labelSelectors:
            app.kubernetes.io/name: cert-manager
    grafana:
      instances:
        - name: lgtm-grafana
          namespace: lgtm
          labelSelectors:
            app.kubernetes.io/name: grafana
    loki:
      instances:
        - name: lgtm-loki
          namespace: lgtm
          labelSelectors:
            app.kubernetes.io/name: loki
    mimir:
      instances:
        - name: lgtm-mimir
          namespace: lgtm
          labelSelectors:
            app.kubernetes.io/name: mimir

mimir-distributed:
  # We have minio at home.
  minio:
    enabled: false
  ingester:
    replicas: 1
    zoneAwareReplication:
      enabled: false
  querier:
    replicas: 1
  query_scheduler:
    replicas: 1
  store_gateway:
    zoneAwareReplication:
      enabled: false
  mimir:
    structuredConfig:
      multitenancy_enabled: false
      memberlist:
        cluster_label: mimir
      common:
        storage:
          backend: s3
          s3:
            endpoint: minio.tales-tenant.svc
            access_key_id: "${ACCESS_KEY_ID}"
            secret_access_key: "${SECRET_ACCESS_KEY}"
      blocks_storage:
        s3:
          bucket_name: mimir-blocks

      alertmanager_storage:
        s3:
          bucket_name: mimir-alertmanager

      ruler_storage:
        s3:
          bucket_name: mimir-ruler
