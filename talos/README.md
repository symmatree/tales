# Talos Linux Setup and Config

## Installation ISO

Image schematic `ce4c980550dd2ab1b17bbf2b08801c7eb59418eafe8f279833297925d67c7515` which
corresponds to:

```
customization:
    systemExtensions:
        officialExtensions:
            - siderolabs/qemu-guest-agent
```

[download link for v1.9.5](https://factory.talos.dev/image/ce4c980550dd2ab1b17bbf2b08801c7eb59418eafe8f279833297925d67c7515/v1.9.5/metal-amd64.iso)

Download the ISO and add to the Synology.

## Installation from scratch (new secrets)

First generate a secrets file. This seems to encapsulate all the generated randomness
at startup, such that you can reuse a talosconfig or kubeconfig file across iterations
as long as they all import the same secrets file.

Master copy of the secrets.yaml is in 1password; `talos/install.sh` extracts it temporarily.

Note that all three files generated by `talosctl gen config` (worker.yaml, controlplane.yaml,
and talosconfig) contain some or all of the secrets; the external secrets file manages
the randomness but does NOT make it safe to version control the resulting files. They should
be completely reproducible given the same command line and patches, along with the external secrets,
but I keep the expanded templates in 1password just in case. (Also handled by the install script.)

### Control node in Talos

* Bring up the control node booted from the CD image.
* Once it's started, edit the boot source to select Virtual HD. (You'll have to do this at some point, might as well while you're here.)

From the top of the repo, I ran

```
cd talos
./install.sh
talosctl apply-config --insecure --nodes 10.0.1.50 --file controlplane.yaml
rm controlplane.yaml
```

I connected to the VM and watched the logs while it incrementally brought things up, until it asks you to bootstrap the
new etcd cluster.

```
talosctl bootstrap -n talos-control-1.local.symmatree.com
```

This will grind a little longer and then sit there complaining about a timeout and a permission denied, but the real problem
is that it doesn't have a CNI so it can't connect to itself.

### Initial Kubernetes config

```
talosctl kubeconfig -n talos-control-1.local.symmatree.com
```

If things are far enough along, this will save or update an entry in your `~/.kube/config` file that gives you the keys to access
the Kubernetes API in the new cluster. (These keys are stable as long as you use the same secrets.yaml file, it seems, but update
it just in case.) Use `kubectl get nodes` or something to confirm you can talk to the API.

I don't want to have to maintain two versions of a `values.yaml` file for Cilium. However, that includes creating some Prometheus monitors
which depend on `prometheus-operator` being installed. There isn't an isolated Helm chart for it any longer, they recommend `kube-prom`
(jsonnet installation of a whole monitoring stack, including prometheus-operator) or a community-maintained Helm clone of that effort. Given that
choice, I want to do `kube-prom` but I don't want to have to install it manually before I even have a CNI. But we can install just the CRDs,
straight from their github repo: `./prometheus-operator-crd/install.sh` (which just makes a series of calls to `kubectl apply`).

## Install Cilium

Now we can install cilium: 

```
./prometheus-operator-crd/install.sh
./cilium/install.sh
```


This installs a small Helm chart of our own, coincidentally named cilium, which exists to install its singular dependency (the actual cilium
Helm chart). This pattern comes from ArgoCD as a way to reuse an external Helm chart with some values overrides.

Note that Cilium will be partially healthy - Hubble Relay and Hubble UI don't have a toleration for the control plane so they won't
schedule just yet.

### Reboot

At this point the core of the control plane is complete. Stop for a moment to shut it down and reboot it with the installed configuration.
Synology's shutdown will work well now, since Talos handles the ACPI event, even though Synology will be worried about it.
Alternatively `talosctl shutdown --wait -n 10.0.1.50` should do the trick.

Just running `talosctl reboot` does NOT have the same effect, primarily that it uses `kexec` to restart the kernel and therefore does not
respect the `vga=` arg that we painstakingly added to get a usable console dashboard. But also it is a good chance to confirm that it will
in fact boot correctly off the Virtual Hard Drive and come back up healthy.

### Worker

The worker is simpler because it does not have to deal with the two-step dance to install Cilium. 

```
talosctl apply-config --insecure --nodes 10.0.1.100 --file worker.yaml
```

Once that applies, do the same shutdown to apply kernel args:

```
talosctl shutdown --wait -n 10.0.1.100
```

Once you restart the VM, it should be green (except for Secure Boot, which, meh).


### Validate installation

```
cilium status --wait -n cilium
kubectl create namespace cilium-test-1 \
  && kubectl label namespace cilium-test-1 pod-security.kubernetes.io/enforce=privileged \
  && kubectl label namespace cilium-test-1 pod-security.kubernetes.io/warn=privileged
cilium connectivity test -n cilium
```

Current issues:

* TODO: `msg="Failed to send gratuitous arp" error="failed to craft ARP reply packet: invalid IPv4 address" ipAddr="invalid IP" k8sPodName= subsys=l2-pod-announcements-garp`

```
# Fails due to single node.
talosctl conformance kubernetes -n 10.0.1.50
```

## Background and Settings

### Memory reservations

#### Summary

TL;DR: Talos doesn't let you customize cgroup settings passed to the kubelet, but does put a MemMax on the `kubepods`
cgroup which ought to do at least some basic protecting of the host compared to the no-reservation defaults.

#### Background

Kubernetes nodes are happy to allocate their entire selves and then effectively die because they cannot
service basic duties like management connections (whether ssh or kubernetes). This can be CPU but
it is most painful with RAM; at work sometomes we see machines go away for minutes or hours, and
sometimes eventually emerge and respond again. Often it takes a long time even after OOM-killing something; this may be
because it killed the wrong thing, or it might be because, before killing it, the node had already
dumped every single cache and memmap out of the working set, and they page back in pathologically.

So, the two strategies to avoid that are

* separate control plane VM so we have someone to talk to even if the worker is fully saturated
* reserve memory for the system so it never gets quite so low, we hope

Docs / inputs

* To see kernel-space usage: `talosctl read -n talos-control.local.symmatree.com /proc/meminfo` and `talosctl read -n 10.0.1.100 /proc/meminfo`
* To see user-space processes: `talosctl processes -n talos-control.local.symmatree.com`
* Allocating processes to owners: [talos component diagram](https://www.talos.dev/v1.9/learn-more/components/)
* [kubernetes compute reservations docs](https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/)
* To see a rather nice rollup: `talosctl cgroups -n talos-control.local.symmatree.com --preset=memory`

I cleaned up the process list, partitioned into categories of based on the kubelet divisions, and added the
`Slab`, `SReclaimable`, `SUnreclaim`, `KernelStack`, and `PageTables` entries from `/proc/meminfo`
as "kernel". (Note that the kernel usage is similar between idle worker and control plane, only
the worker has KernelStack and PageTables which makes perfect sense since I had no load running).

Upshot:

| type        | SUM of RESMEM MB |
| ----------- | ---------------- |
| kernel      | 123              |
| kube        | 441              |
| pod         | 920              |
| system      | 253              |
| Grand Total | 1737             |

There is not much distinction between "host" and "talos", I was just trying to identify process
names more easily. In more detail:

| type   | RESMEM MB | COMMAND                                |
| ------ | --------- | -------------------------------------- |
| pod    | 496       | /usr/local/bin/kube-apiserver          |
| kube   | 166       | /usr/local/bin/etcd                    |
| pod    | 122       | /usr/bin/cilium-agent                  |
| system | 104       | /sbin/init                             |
| pod    | 87        | /usr/local/bin/kube-controller-manager |
| kube   | 73        | /usr/local/bin/kubelet                 |
| pod    | 58        | /usr/bin/cilium-operator-generic       |
| system | 56        | /sbin/dashboard                        |
| kernel | 54        | Slab:                                  |
| system | 46        | /apid                                  |
| kube   | 45        | /bin/containerd                        |
| system | 44        | /trustd                                |
| pod    | 44        | /coredns                               |
| pod    | 44        | /usr/local/bin/kube-scheduler          |
| pod    | 43        | /coredns                               |
| kernel | 41        | SUnreclaim:                            |
| kube   | 21        | /bin/containerd                        |
| pod    | 20        | /usr/bin/cilium-envoy                  |
| kernel | 13        | SReclaimable:                          |
| kube   | 12        | /bin/containerd-shim-runc-v2           |
| kube   | 12        | /bin/containerd-shim-runc-v2           |
| kube   | 12        | /bin/containerd-shim-runc-v2           |
| kube   | 12        | /bin/containerd-shim-runc-v2           |
| kube   | 11        | /bin/containerd-shim-runc-v2           |
| kube   | 11        | /bin/containerd-shim-runc-v2           |
| kube   | 11        | /bin/containerd-shim-runc-v2           |
| kube   | 11        | /bin/containerd-shim-runc-v2           |
| kube   | 11        | /bin/containerd-shim-runc-v2           |
| kube   | 11        | /bin/containerd-shim-runc-v2           |
| kube   | 11        | /bin/containerd-shim-runc-v2           |
| kube   | 11        | /bin/containerd-shim-runc-v2           |
| kernel | 8         | PageTables:                            |
| kernel | 8         | KernelStack:                           |
| pod    | 6         | /usr/bin/cilium-health-responder       |
| system | 3         | /sbin/systemd-udevd                    |

This is just a snapshot (of a totally idle system with a worker
that did not get a PodCIDR and is broken), but good enough to go on with, considering that the
default reservation is 0.

Lol okay I think `talosctl cgroups -n talos-control.local.symmatree.com --preset=memory` is actually all I need,
since it has them broken into `podruntime`, `system`, and `kubepods` cgroups, with current and peak RAM for each.

Okay what do these columns mean? [kernel docs](https://docs.kernel.org/admin-guide/cgroup-v2.html)

* `memory.low`

> Best-effort memory protection. If the memory usage of a cgroup is within its effective low boundary, the cgroup’s memory won’t be reclaimed unless there is no reclaimable memory available in unprotected cgroups. 

* `memory.high`

> Memory usage throttle limit. If a cgroup’s usage goes over the high boundary, the processes of the cgroup are throttled and put under heavy reclaim pressure.

> Going over the high limit never invokes the OOM killer and under extreme conditions the limit may be breached. The high limit should be used in scenarios where an external process monitors the limited cgroup to alleviate heavy reclaim pressure.

* `memory.max`

> Memory usage hard limit. This is the main mechanism to limit memory usage of a cgroup. If a cgroup’s memory usage reaches this limit and can’t be reduced, the OOM killer is invoked in the cgroup. Under certain circumstances, the usage may go over the limit temporarily.

Currently:

* MemLow is set for `init`, tasks under `podruntime`, `system` and some tasks under it.
* MemHigh is totally unset
* MemMax is set for `kubepods` (this might be Allocatable?), `coredns` within it, and `apid`, `dashboard` and `trustd` within `system`
* Currently (new, idle system) every MemPeak is less than MemLow as well as (almost-of-course) MemMax.
